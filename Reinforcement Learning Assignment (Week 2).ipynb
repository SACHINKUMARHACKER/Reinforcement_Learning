{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HomeWork Assignment (Week 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title functions to evaluate how good our policy is\n",
    "'''def runPolicy(env,policy):\n",
    "    state = env.reset\n",
    "    done = False\n",
    "    totalReward = 0\n",
    "    while not done:\n",
    "        state,reward,done,_ = env.step(policy[state])\n",
    "        totalReward += reward\n",
    "    return totalReward'''\n",
    "def runPolicy(env, policy):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "  \n",
    "    totalReward = 0\n",
    "    while not done:\n",
    "        state, reward, done, _ = env.step(policy[state])\n",
    "        totalReward += reward\n",
    "    return totalReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePolicy(env,policy,iterations):\n",
    "    totalRewards = 0\n",
    "    for i in range(iterations):\n",
    "        totalRewards += runPolicy(env,policy)\n",
    "    return totalRewards/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructGreedyPolicy(env,values,gamma):\n",
    "    policy = np.zeros(env.env.nS)\n",
    "    for s in range(env.env.nS):\n",
    "        returns = [sum(p*(r+gamma*values[ns]) for p,ns,r,_ in env.env.P[s][a]) for a in range(env.env.nA)]\n",
    "        policy[s] = np.argmax(returns)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeStateValues(env,gamma,policy=None,selectBest=False):\n",
    "    if policy is None and not selectBest:\n",
    "        raise 'When using computeStateValues either specify policy or pass selectBest=True'\n",
    "    if policy is not None and selectBest:\n",
    "        raise 'You cannot use policy and selectBest at the same time'\n",
    "    values = np.zeros(env.env.nS)\n",
    "    while True:\n",
    "        nextValues = values.copy()\n",
    "        for s in range(env.env.nS):\n",
    "            if policy is not None:\n",
    "                action = policy[s]\n",
    "                nextValues[s] = sum(p*(r+gamma*values[ns]) for p,ns,r,_ in env.env.P[s][action])\n",
    "            else:\n",
    "                nextValues[s] = max(sum(p*(r+gamma*values[ns]) for p,ns,r,_ in env.env.P[s][a]) for a in range(env.env.nA))\n",
    "        diff = np.fabs(nextValues-values).sum()\n",
    "        values = nextValues\n",
    "        if diff <= eps:\n",
    "            break\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valueIteration(env,gamma):\n",
    "    stateValues = computeStateValues(env,gamma,selectBest=True)\n",
    "    policy = constructGreedyPolicy(env,stateValues,gamma)\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomPolicy(env):\n",
    "    return np.random.choice(env.env.nA,size=(env.env.nS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policyIteration(env,gamma):\n",
    "    policy=randomPolicy(env)\n",
    "    while True:\n",
    "        stateValues = computeStateValues(env,gamma,policy)\n",
    "        nextPolicy = constructGreedyPolicy(env,stateValues,gamma)\n",
    "        if np.all(policy == nextPolicy):\n",
    "            break\n",
    "        policy = nextPolicy\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateIterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveEnv(env,methods,envName):\n",
    "    print(f'Solving environment {envName}')\n",
    "    for method in methods:\n",
    "        name,f,gamma = method\n",
    "        tstart = time.time()\n",
    "        policy = f(env,gamma)\n",
    "        tend = time.time()\n",
    "        print(f'It took {tend-tstart} seconds to compute a policy using \"{name}\" with gamma = {gamma}')\n",
    "        score = evaluatePolicy(env,policy,evaluateIterations)\n",
    "        print(f'Policy average reward is {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\n",
    "    ('Value Iteration',valueIteration,0.9),\n",
    "    ('Policy Iteration',policyIteration,0.9),\n",
    "    ('Value Iteration',valueIteration,0.98),\n",
    "    ('Policy Iteration',policyIteration,0.98),\n",
    "    ('Value Iteration',valueIteration,1),\n",
    "    ('Policy Iteration',policyIteration,1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment Frozen Lake 4x4\n",
      "It took 0.04993295669555664 seconds to compute a policy using \"Value Iteration\" with gamma = 0.9\n",
      "Policy average reward is 0.73\n",
      "It took 0.09299612045288086 seconds to compute a policy using \"Policy Iteration\" with gamma = 0.9\n",
      "Policy average reward is 0.726\n",
      "It took 0.14175009727478027 seconds to compute a policy using \"Value Iteration\" with gamma = 0.98\n",
      "Policy average reward is 0.744\n",
      "It took 0.15947580337524414 seconds to compute a policy using \"Policy Iteration\" with gamma = 0.98\n",
      "Policy average reward is 0.753\n",
      "It took 0.2913358211517334 seconds to compute a policy using \"Value Iteration\" with gamma = 1\n",
      "Policy average reward is 0.73\n",
      "It took 0.23656439781188965 seconds to compute a policy using \"Policy Iteration\" with gamma = 1\n",
      "Policy average reward is 0.747\n"
     ]
    }
   ],
   "source": [
    "frozenLake4 = gym.make('FrozenLake-v0')\n",
    "solveEnv(frozenLake4,methods,'Frozen Lake 4x4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
